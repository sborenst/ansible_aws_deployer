# vim: set ft=ansible:
---
- name: Starting environment deployment
  hosts: localhost
  connection: local
  gather_facts: False
  vars_files:
  - "../Environments/{{ config }}_vars.yml"
  - "../Environments/{{ config }}_secret_vars.yml"

  tasks:

######################### Generate CF Template
######################### Launch CF Template

  - name: Provisioning Environment
    gather_facts: False
    vars_files:
    - "../Environments/{{ config }}_vars.yml"
    - "../Environments/{{ config }}_secret_vars.yml"
    include: ./provision_cf.yml
    tags:
      - provisioning
      - gen_cf_template
      - provision_cf_template


######################### Populate Dynamic Inventory

  - name: Creating Dynamic Inventory
    gather_facts: False
    vars_files:
    - "../Environments/{{ config }}_vars.yml"
    - "../Environments/{{ config }}_secret_vars.yml"
    include: ./dynamic_inventory.yml
    tags:
      - dynamic_inventory
      - get_hosts
      - populate_hosts
      - generate_ansible_host_file


######################### LOCAL Bastion Proxy Config

  - name: Generate ssh.cfg Template
    template:
      src: files/ssh.cfg.j2
      dest: ../workdir/ssh-{{ config }}-{{ guid }}.cfg
    tags:
      - bastion_proxy_config
      - create_ssh_cfg_template

## Need to add a check here to see if this was already done
# TODO: Sha, do we need to append or can we replace all entries in ssh config?
  - name: copy ssh.cfg into local ~.ssh/Config
    shell: "cat ../workdir/ssh-{{ config }}-{{ guid }}.cfg >> ~/.ssh/config"
    tags:
      - bastion_proxy_config
      - workaround
      - config_ssh_config_file

######################### Run COMMON Tasks on all hosts

- name: Wait for readiness
  hosts: bastions
  vars_files:
    - "../Environments/{{ config }}_vars.yml"
  gather_facts: False
  any_errors_fatal: true
  tags:
    - wait_ssh
  tasks:
    - name: wait for host to be available
      wait_for:
        host: '{{ inventory_hostname }}'
        port: 22
        search_regex: OpenSSH
      with_items: "{{ groups['allhosts'] }}"

- name: Configuring common Hosts
  hosts: bastions,nfs,masters,infranodes,nodes
  become: yes
  any_errors_fatal: true
  vars_files:
    - "../Environments/{{ config }}_vars.yml"
    - "../Environments/{{ config }}_secret_vars.yml"
  roles:
    - common
  tags:
    - common_tasks


######################### Run bastion Tasks



- name: Configuring Bastion Hosts
  hosts: bastions
  become: yes
  vars_files:
    - "../Environments/{{ config }}_vars.yml"
  roles:
    - bastion
  tags:
    - bastion_tasks


#########################Configuring nfs Host

- name: Configuring nfs Host
  hosts: nfs
  become: yes
  vars_files:
    - "../Environments/{{ config }}_vars.yml"
  roles:
    - nfs
  tags:
    - nfs_tasks

- name: Configuring nfs Host
  hosts: nfs
  become: yes
  vars_files:
    - "../Environments/{{ config }}_vars.yml"
  tasks:
    - file:
        path: '{{ nfs_export_path }}/user-vols/vol{1..{{ user_vols }}}'
        state: directory
        mode: 0777
        recurse: yes
  tags:
    - nfs_tasks
## TODO: Remove the next three lines after testing
#    - shell 'mkdir -p {{ nfs_export_path }}/user-vols/vol{1..{{ user_vols }}}'
#    - shell: 'chown -R {{ nfs_export_path }}/user-vols/vol{1..{{ user_vols }}}'
#    - shell: 'chmod -R 0777 {{ nfs_export_path }}/user-vols/vol{1..{{ user_vols }}}'

####################### Startring OpenShift Specific Deployment

#########################Configuring openshfit-provisioner

- name: Configuring openshfit-provisioner
  hosts: bastions
  become: yes
  vars_files:
    - "../Environments/{{ config }}_vars.yml"
  roles:
    - openshift-provisioner
  tags:
    - openshift_provisioner_tasks


#########################Configuring openshfit-nodes

- name: Configuring openshift-nodes
  hosts: infranodes,nodes
  become: yes
  vars_files:
    - "../Environments/{{ config }}_vars.yml"
  roles:
    - openshift-node
  tags:
    - openshift_node_tasks


######################### Run OpenShift Installer


- name: Run OpenShift Installer
  hosts: bastions
  become: yes
  vars_files:
    - "../Environments/{{ config }}_vars.yml"
  tags:
    - installing_openshift
  tasks:

    - name: Add log path to Ansible configuration
      lineinfile:
        regexp: "^#log_path"
        dest: "/etc/ansible/ansible.cfg"
        line: "log_path = /root/ansible.log"
        state: present

##TODO: Just use -include: /usr/share/ansible/openshift-ansible/playbooks/byo/config.yml"
    - name: run ansible-playbook -i /etc/ansible/hosts /usr/share/ansible/openshift-ansible/playbooks/byo/config.yml
      shell: "ansible-playbook -i /etc/ansible/hosts /usr/share/ansible/openshift-ansible/playbooks/byo/config.yml"
      register: openshift_install_log
      tags:
        - openshfit_installer

##TODO: Use file module or fetch module
    - name: get openshfit credentials file
      shell: ansible masters[0] -b -m fetch -a "src=/root/.kube/config dest=/root/.kube/config flat=yes"
      tags:
        - get_openshift_credentials

######################### Create user-vols PVs
- name: Create user-vols PVs
  hosts: bastions
  become: yes
  vars_files:
    - "../Environments/{{ config }}_vars.yml"
  tags:
    - create_user_vol_pvs
  tasks:
    - set_fact:
        pv_size: '10Gi'
        pv_list: "{{ nfs_shares }}"
        persistentVolumeReclaimPolicy: Retain

    - name: Generate PV file
      template:
        src: files/{{ config }}_pvs.j2
        dest: /root/pvs-{{ config }}-{{ guid }}.yml
      tags:
        - testing

    - set_fact:
        pv_size: "{{ user_vols_size }}"
        persistentVolumeReclaimPolicy: Recycle
    - name: Generate user vol PV file
      template:
        src: files/ocp-ml_userpvs.j2
        dest: /root/userpvs-{{ config }}-{{ guid }}.yml
      tags:
        - testing

##TODO: Add handling with failed_when
    - shell: 'oc create -f /root/pvs-{{ config }}-{{ guid }}.yml || oc update -f /root/pvs-{{ config }}-{{ guid }}.yml'
      become: true
    - shell: 'oc create -f /root/userpvs-{{ config }}-{{ guid }}.yml || oc update -f /root/userpvs-{{ config }}-{{ guid }}.yml'
      become: true

######################### Workshop specific
- name: Workshop admins
  hosts: masters
  become: yes
  vars_files:
    - "../Environments/{{ config }}_vars.yml"
  tags:
    - workshop
    - workshop_admins
  tasks:

##TODO: htpasswd module
  - name: Add administrative user to htpasswd file
    command: "htpasswd -b /etc/origin/master/htpasswd admin openshift3"

- name: Create Workshop NFS shares
  hosts: nfs
  become: yes
  vars_files:
    - "../Environments/{{ config }}_vars.yml"
  tags:
    - workshop
    - workshop_nfs
  tasks:
    - name: Create workshop nfs directory
      file:
        name: '/srv/nfs/{{ item }}'
        state: directory
        mode: 0777
        owner: nfsnobody
        group: nfsnobody
        recurse: True
      with_items:
        - '{{ workshop_shares }}'

    - name: Create workshop exports file
      file:
        path: /etc/exports.d/{{ config }}-{{ guid }}-workshop.exports
        state: touch
        mode: 755

    - name: Update workshop exports file
      lineinfile:
        dest: /etc/exports.d/{{ config }}-{{ guid }}-workshop.exports
        line: '/srv/nfs/{{ item }} *(rw,root_squash,no_wdelay,sync)'
        state: present
      with_items:
        - '{{ workshop_shares }}'
      run_once: True

    - name: Reload NFS exports
      shell: "exportfs -r"

- name: Workshop PVs
  hosts: masters
  become: yes
  vars_files:
    - "../Environments/{{ config }}_vars.yml"
  tags:
    - workshop
    - create_workshop_vol_pvs
  tasks:
    - set_fact:
        pv_size: '10Gi'
        pv_list: "{{ workshop_shares }}"
        persistentVolumeReclaimPolicy: Retain

    - name: Generate workshop PV file
      template:
        src: files/{{ config }}_pvs.j2
        dest: /root/pvs-{{ config }}-{{ guid }}.yml

##TODO: Add failed_when condition and handling
    - name: Create workshop PVs
      shell: 'oc create -f /root/pvs-{{ config }}-{{ guid }}.yml || oc update -f /root/pvs-{{ config }}-{{ guid }}.yml'

- name: Workshop infrastructure
  hosts: masters
  become: yes
  vars_files:
    - "../Environments/{{ config }}_vars.yml"
  tags:
    - workshop
    - workshop_infra
  tasks:

    - name: 'Copy pipelines extension script to server'
      copy:
        src: files/bu-workshop/tech-preview.js
        dest: /etc/origin/master/tech-preview.js

    - name: 'Check for the extensionScripts directive in the master config'
      command: "grep extensionScripts /etc/origin/master/master-config.yaml"
      ignore_errors: true
      register: grep_script_out

    - name: Update master config to reference extension script
      shell:
        sed -i -s '/assetConfig:/a\  extensionScripts:\n\    - /etc/origin/master/tech-preview.js' /etc/origin/master/master-config.yaml
      register: tech_preview_config
      when: grep_script_out | failed

    - name: 'Restart master for changed extension script directive'
      shell: "systemctl restart atomic-openshift-master"
      when: grep_script_out | failed

    - name: Give administrative user cluster-admin privileges
      command: "oc adm policy add-cluster-role-to-user cluster-admin admin"

    - name: Check for workshop-infra project
      command: "oc get project workshop-infra"
      register: result
      ignore_errors: true

    - name: Create workshop-infra project
      command: "oc adm new-project workshop-infra --admin admin --node-selector='region=infra'"
      when: result | failed

    - name: Make workshop-infra project network global
      command: "oc adm pod-network make-projects-global workshop-infra"

    - name: Set workshop-infra SCC for anyuid
      command: "oc adm policy add-scc-to-group anyuid system:serviceaccounts:workshop-infra"

    - name: Add capabilities within anyuid which is not really ideal
      command: "oc patch scc/anyuid --patch '{\"requiredDropCapabilities\":[\"MKNOD\",\"SYS_CHROOT\"]}'"

    - name: Copy nexus.yaml to master
      copy:
        src: files/bu-workshop/nexus.yaml
        dest: /root/nexus.yaml

    - name: Check if Nexus was already provisioned
      command: "oc get service nexus -n workshop-infra"
      register: install_nexus
      ignore_errors: true

    - name: Instantiate nexus from template
      command: "oc create -f /root/nexus.yaml -n workshop-infra"
      when: install_nexus | failed

    # looks like we need a better check - it seems we're ready up to several
    # seconds before the router finds out about us, so we might want another
    # http check to make sure nexus is responding
    - name: Wait for Nexus to be running
      command: "oc get dc/nexus -o yaml -n workshop-infra"
      register: result
      until: '"availableReplicas: 1" in result.stdout'
      retries: 5
      delay: 60

    - name: Wait for Nexus to be happy
      uri:
        url: "http://nexus.workshop-infra.svc.cluster.local:8081/content/repositories/"
        status_code: 200
      register: nexus_happy
      until: nexus_happy | success
      retries: 5
      delay: 60

    - name: Install EPEL (for jq)
      package:
        name: "https://dl.fedoraproject.org/pub/epel/epel-release-latest-7.noarch.rpm"
        state: installed

    - name: Disable EPEL
      command: "yum-config-manager --disablerepo=epel"

    - name: Install jq
      package:
        name: jq
        state: present
        enablerepo: epel

    - name: Copy Nexus addrepo script
      copy:
        src: files/bu-workshop/addrepo.sh
        dest: /root/addrepo.sh

    - name: Check for redhat-ga repository in Nexus
      uri:
        url: "http://nexus.workshop-infra.svc.cluster.local:8081/content/repositories/redhat-ga"
        status_code: 200
      register: redhat_ga_out
      ignore_errors: true

    - name: Add redhat-ga repository for Nexus
      shell: "NEXUS_BASE_URL=nexus.workshop-infra.svc.cluster.local:8081 bash /root/addrepo.sh redhat-ga https://maven.repository.redhat.com/ga/"
      when: redhat_ga_out | failed

    - name: Check for JBoss repository in Nexus
      uri:
        url: "http://nexus.workshop-infra.svc.cluster.local:8081/content/repositories/jboss"
        status_code: 200
      register: redhat_ga_out
      ignore_errors: true

    - name: Add redhat-ga repository for Nexus
      shell: "NEXUS_BASE_URL=nexus.workshop-infra.svc.cluster.local:8081 bash /root/addrepo.sh jboss https://repository.jboss.org/nexus/content/repositories/public"
      when: redhat_ga_out | failed

    - name: Copy gitlab-template.yaml to master
      copy:
        src: files/bu-workshop/gitlab-template.yaml
        dest: /root/gitlab-template.yaml

    - name: Check if Gitlab was already provisioned
      command: "oc get service gitlab-ce -n workshop-infra"
      register: install_gitlab
      ignore_errors: true

    - name: Instantiate Gitlab from template
      shell: >
        oc process -f /root/gitlab-template.yaml
        -v APPLICATION_HOSTNAME=gitlab-ce-workshop-infra.{{cloudapps_suffix}}
        -v GITLAB_ROOT_PASSWORD=password | oc create -f - -n workshop-infra
      when: install_gitlab | failed
      tags:
        - "instantiate-gitlab"

    - name: Wait for Gitlab to be running
      command: "oc get dc/gitlab-ce -o yaml -n workshop-infra"
      register: result
      until: '" availableReplicas: 1" in result.stdout'
      retries: 8
      delay: 60
      tags:
        - "wait-for-gitlab"

    - name: Copy simple-java-s2i IS to server
      copy:
        src: files/bu-workshop/java-s2i-is.yaml
        dest: /root/java-s2i-is.yaml
      tags:
        - "copy-java-s2i-is"

    - name: Create simple-java-s2i IS in openshift namespace
      shell: "oc create -f /root/java-s2i-is.yaml -n openshift || oc replace -f /root/java-s2i-is.yaml -n openshift"
      tags:
        - "create-java-s2i-is"

    - name: Create Jenkins pipeline template in openshift namespace
      shell: " oc create -f https://raw.githubusercontent.com/openshift-roadshow/nationalparks/1.0.0/ose3/pipeline-template.yaml -n openshift || oc replace -f https://raw.githubusercontent.com/openshift-roadshow/nationalparks/1.0.0/ose3/pipeline-template.yaml -n openshift"
      tags:
        - "create-pipeline-template"

    - name: Check for workshop lab build
      command: "oc get svc/labs -n workshop-infra"
      ignore_errors: true
      register: labs_service_out

    - name: Build workshop lab server
      shell: >
        oc new-app
        --name=labs https://github.com/openshift-evangelists/openshift-workshops.git#1.0.0 \
        -e ROUTER_ADDRESS={{cloudapps_suffix}}
        -e CONSOLE_ADDRESS=master.{{subdomain_base}}
        -e DEFAULT_LAB=roadshow
        -n workshop-infra;
        oc expose service labs -n workshop-infra
      when: labs_service_out | failed
      tags:
        - "build-workshop-labs"

- name: GitLab nfs permissions hack
  hosts: nfs
  become: yes
  vars_files:
    - "../Environments/{{ config }}_vars.yml"
  tags:
    - workshop
    - workshop_nfs_hack
  tasks:
##TODO: Combine all of these under the file module for idempotency
    - name: Fix ownership of git-data
      shell: "chown -R 998:root /srv/nfs/gitlab-data"

    - name: Fix permission on git-data
      shell: "chmod -R 700 /srv/nfs/gitlab-data/git-data"

    - name: Fix permission on git-data/repositories
      shell: "chmod -R 2770 /srv/nfs/gitlab-data/git-data/repositories"

- name: Project Request Template
  hosts: masters
  become: yes
  vars_files:
    - "../Environments/{{ config }}_vars.yml"
  tags:
    - workshop
    - project_request
  tasks:

    - name: Copy project request template to master
      copy:
        src: files/bu-workshop/project-template.yaml
        dest: /root/project-template.yaml

    - name: Check for project request template
      command: "oc get template project-request -n default"
      register: request_template
      ignore_errors: true

    - name: Create project request template in default project
      shell: "oc create -f /root/project-template.yaml -n default || oc replace -f /root/project-template.yaml -n default"
      when: request_template | failed

    - name: Update master config file to use project request template
      lineinfile:
        regexp: "  projectRequestTemplate"
        dest: "/etc/origin/master/master-config.yaml"
        line: '  projectRequestTemplate: "default/project-request"'
        state: present
      register: master_config

    - name: Restart master service
      service:
        name: atomic-openshift-master
        state: restarted
      when: master_config.changed

- name: Workshop Users
  hosts: masters
  become: yes
  vars_files:
    - "../Environments/{{ config }}_vars.yml"
  tags:
    - workshop
    - workshop_users
  tasks:

    - name: Add log path to Ansible configuration
      lineinfile:
        regexp: "^#log_path"
        dest: "/etc/ansible/ansible.cfg"
        line: "log_path = /root/ansible.log"
        state: present

    - name: Copy vars file to master
      copy:
        src: "../Environments/{{ config }}_vars.yml"
        dest: "/root/{{ config }}_vars.yml"

    - name: Copy user provision Ansible script remotely
      copy:
        src: files/bu-workshop/userprovision.yaml
        dest: /root/userprovision.yaml

    - name: Set Gitlab internal hostname
      set_fact:
        gitlab_hostname: 'gitlab-ce.workshop-infra.svc.cluster.local'

    - name: Get root user token
      uri:
        url: 'http://gitlab-ce.workshop-infra.svc.cluster.local/api/v3/session'
        body: 'login=root&password=password'
        method: POST
        status_code: 201
      register: root_token_out
      until: root_token_out|success
      retries: 3
      delay: 60

    - name: Create root token fact
      set_fact:
        root_token: '{{root_token_out.json.private_token}}'

    - name: Execute user provision Ansible script remotely
      shell: >
        ansible-playbook
        -i localhost /root/userprovision.yaml
        -e config={{ config }}
        -e user={{item}}
        -e root_token={{root_token}}
        -e gitlab_hostname={{gitlab_hostname}}
      with_sequence: start=0 end={{ user_vols }} format=%02d

- name: Cache Java dependencies
  hosts: masters
  become: yes
  vars_files:
    - "../Environments/{{ config }}_vars.yml"
  vars:
    workshop_repos:
      - "nationalparks"
      - "mlbparks"
      - "parksmap-web"
  tags: [ workshop, workshop_java_dependencies ]
  tasks:
    - name: Install Maven and Java
      yum:
        name: '{{ item }}'
        state: present
        enablerepo: "rhui-REGION-rhel-server-optional"
      with_items:
        - "maven"
        - "java-1.8.0-openjdk-devel"

    - name: Remove m2 folder
      file:
        path: "/home/ec2-user/.m2/repository"
        state: absent

    - name: Make repos directory
      file:
        path: "/home/ec2-user/repos"
        state: directory

    - name: Clone app repositories
      git:
        repo: 'https://github.com/openshift-roadshow/{{ item }}'
        dest: "/home/ec2-user/repos/{{ item }}"
      with_items: '{{workshop_repos}}'

    - name: Deploy maven settings file
      template:
        src: files/bu-workshop/maven.xml.j2
        dest: /home/ec2-user/maven.xml
        mode: 0755
        owner: ec2-user

    - name: Build and cache dependencies
      shell: >
        mvn -q -s /home/ec2-user/maven.xml -f /home/ec2-user/repos/{{ item }}/pom.xml install
      with_items: '{{workshop_repos}}'
